{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Machine Learning - Logistic Regression\n",
    "\n",
    "## Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2fc86907e48d905f"
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_data = pd.read_csv('../data/raw/dataset_train.csv').dropna()\n",
    "\n",
    "# Remove the columns that are not features and standardize the data\n",
    "def standardize(x):\n",
    "    means = np.mean(x, axis=0)\n",
    "    stds = np.std(x, axis=0)\n",
    "\n",
    "    stds[stds == 0] = 1\n",
    "    return (x - means) / stds\n",
    "train_data_filtered = train_data.drop(columns = ['Hogwarts House', 'First Name', 'Last Name', 'Birthday', 'Best Hand', 'Index', 'Astronomy', 'Arithmancy', 'Care of Magical Creatures'])\n",
    "x_train_standardized = standardize(train_data_filtered)\n",
    "\n",
    "y_true = {\n",
    "    'gryffindor': (train_data['Hogwarts House'] == 'Gryffindor').astype(int),\n",
    "    'slytherin': (train_data['Hogwarts House'] == 'Slytherin').astype(int),\n",
    "    'ravenclaw': (train_data['Hogwarts House'] == 'Ravenclaw').astype(int),\n",
    "    'hufflepuff': (train_data['Hogwarts House'] == 'Hufflepuff').astype(int)\n",
    "}\n",
    "train_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T00:16:27.755045Z",
     "start_time": "2024-07-18T00:16:15.892489Z"
    }
   },
   "id": "122c4fb2d940115f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      Index Hogwarts House First Name    Last Name    Birthday Best Hand  \\\n",
       "0         0      Ravenclaw     Tamara          Hsu  2000-03-30      Left   \n",
       "1         1      Slytherin      Erich      Paredes  1999-10-14     Right   \n",
       "2         2      Ravenclaw   Stephany        Braun  1999-11-03      Left   \n",
       "3         3     Gryffindor      Vesta    Mcmichael  2000-08-19      Left   \n",
       "5         5      Slytherin    Corrine      Hammond  1999-04-04     Right   \n",
       "...     ...            ...        ...          ...         ...       ...   \n",
       "1595   1595     Gryffindor       Jung        Blank  2001-09-14     Right   \n",
       "1596   1596      Slytherin     Shelli         Lock  1998-03-12      Left   \n",
       "1597   1597     Gryffindor   Benjamin  Christensen  1999-10-24     Right   \n",
       "1598   1598     Hufflepuff  Charlotte       Dillon  2001-09-21      Left   \n",
       "1599   1599     Hufflepuff      Kylie        Nowak  2000-08-21      Left   \n",
       "\n",
       "      Arithmancy   Astronomy  Herbology  Defense Against the Dark Arts  \\\n",
       "0        58384.0 -487.886086   5.727180                       4.878861   \n",
       "1        67239.0 -552.060507  -5.987446                       5.520605   \n",
       "2        23702.0 -366.076117   7.725017                       3.660761   \n",
       "3        32667.0  697.742809  -6.497214                      -6.977428   \n",
       "5        21209.0 -613.687160  -4.289197                       6.136872   \n",
       "...          ...         ...        ...                            ...   \n",
       "1595     49009.0  354.280086  -4.541837                      -3.542801   \n",
       "1596     63296.0  367.531174   6.061064                      -3.675312   \n",
       "1597     63905.0  544.018925  -3.203269                      -5.440189   \n",
       "1598     82713.0  453.676219   3.442831                      -4.536762   \n",
       "1599     48639.0  688.911989   5.421046                      -6.889120   \n",
       "\n",
       "      Divination  Muggle Studies  Ancient Runes  History of Magic  \\\n",
       "0          4.722      272.035831     532.484226          5.231058   \n",
       "1         -5.612     -487.340557     367.760303          4.107170   \n",
       "2          6.140      664.893521     602.585284          3.555579   \n",
       "3          4.026     -537.001128     523.982133         -4.809637   \n",
       "5         -6.592     -440.997704     396.201804          5.380286   \n",
       "...          ...             ...            ...               ...   \n",
       "1595       5.702     -497.235066     618.220213         -5.231721   \n",
       "1596       1.757     -643.271092     445.827565          2.238112   \n",
       "1597       6.065     -385.150457     635.211486         -5.984257   \n",
       "1598       6.738     -831.741123     383.444937          3.813111   \n",
       "1599       6.593     -234.207911     339.775154          7.208415   \n",
       "\n",
       "      Transfiguration    Potions  Care of Magical Creatures     Charms  Flying  \n",
       "0         1039.788281   3.790369                   0.715939 -232.79405  -26.89  \n",
       "1         1058.944592   7.248742                   0.091674 -252.18425 -113.45  \n",
       "2         1088.088348   8.728531                  -0.515327 -227.34265   30.42  \n",
       "3          920.391449   0.821911                  -0.014040 -256.84675  200.64  \n",
       "5         1052.845164  11.751212                   1.049894 -247.94549  -34.69  \n",
       "...               ...        ...                        ...        ...     ...  \n",
       "1595       964.219853   3.389086                  -0.649983 -250.39401  185.83  \n",
       "1596      1056.147366   5.825263                  -0.333962 -246.42719   44.80  \n",
       "1597       953.866685   1.709808                   0.071569 -251.63679  198.47  \n",
       "1598      1087.949205   3.904100                  -0.531875 -246.19072  -76.81  \n",
       "1599      1034.928004   2.052215                   0.150532 -244.02063  -54.77  \n",
       "\n",
       "[1251 rows x 19 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Hogwarts House</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Birthday</th>\n",
       "      <th>Best Hand</th>\n",
       "      <th>Arithmancy</th>\n",
       "      <th>Astronomy</th>\n",
       "      <th>Herbology</th>\n",
       "      <th>Defense Against the Dark Arts</th>\n",
       "      <th>Divination</th>\n",
       "      <th>Muggle Studies</th>\n",
       "      <th>Ancient Runes</th>\n",
       "      <th>History of Magic</th>\n",
       "      <th>Transfiguration</th>\n",
       "      <th>Potions</th>\n",
       "      <th>Care of Magical Creatures</th>\n",
       "      <th>Charms</th>\n",
       "      <th>Flying</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ravenclaw</td>\n",
       "      <td>Tamara</td>\n",
       "      <td>Hsu</td>\n",
       "      <td>2000-03-30</td>\n",
       "      <td>Left</td>\n",
       "      <td>58384.0</td>\n",
       "      <td>-487.886086</td>\n",
       "      <td>5.727180</td>\n",
       "      <td>4.878861</td>\n",
       "      <td>4.722</td>\n",
       "      <td>272.035831</td>\n",
       "      <td>532.484226</td>\n",
       "      <td>5.231058</td>\n",
       "      <td>1039.788281</td>\n",
       "      <td>3.790369</td>\n",
       "      <td>0.715939</td>\n",
       "      <td>-232.79405</td>\n",
       "      <td>-26.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Slytherin</td>\n",
       "      <td>Erich</td>\n",
       "      <td>Paredes</td>\n",
       "      <td>1999-10-14</td>\n",
       "      <td>Right</td>\n",
       "      <td>67239.0</td>\n",
       "      <td>-552.060507</td>\n",
       "      <td>-5.987446</td>\n",
       "      <td>5.520605</td>\n",
       "      <td>-5.612</td>\n",
       "      <td>-487.340557</td>\n",
       "      <td>367.760303</td>\n",
       "      <td>4.107170</td>\n",
       "      <td>1058.944592</td>\n",
       "      <td>7.248742</td>\n",
       "      <td>0.091674</td>\n",
       "      <td>-252.18425</td>\n",
       "      <td>-113.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Ravenclaw</td>\n",
       "      <td>Stephany</td>\n",
       "      <td>Braun</td>\n",
       "      <td>1999-11-03</td>\n",
       "      <td>Left</td>\n",
       "      <td>23702.0</td>\n",
       "      <td>-366.076117</td>\n",
       "      <td>7.725017</td>\n",
       "      <td>3.660761</td>\n",
       "      <td>6.140</td>\n",
       "      <td>664.893521</td>\n",
       "      <td>602.585284</td>\n",
       "      <td>3.555579</td>\n",
       "      <td>1088.088348</td>\n",
       "      <td>8.728531</td>\n",
       "      <td>-0.515327</td>\n",
       "      <td>-227.34265</td>\n",
       "      <td>30.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Gryffindor</td>\n",
       "      <td>Vesta</td>\n",
       "      <td>Mcmichael</td>\n",
       "      <td>2000-08-19</td>\n",
       "      <td>Left</td>\n",
       "      <td>32667.0</td>\n",
       "      <td>697.742809</td>\n",
       "      <td>-6.497214</td>\n",
       "      <td>-6.977428</td>\n",
       "      <td>4.026</td>\n",
       "      <td>-537.001128</td>\n",
       "      <td>523.982133</td>\n",
       "      <td>-4.809637</td>\n",
       "      <td>920.391449</td>\n",
       "      <td>0.821911</td>\n",
       "      <td>-0.014040</td>\n",
       "      <td>-256.84675</td>\n",
       "      <td>200.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Slytherin</td>\n",
       "      <td>Corrine</td>\n",
       "      <td>Hammond</td>\n",
       "      <td>1999-04-04</td>\n",
       "      <td>Right</td>\n",
       "      <td>21209.0</td>\n",
       "      <td>-613.687160</td>\n",
       "      <td>-4.289197</td>\n",
       "      <td>6.136872</td>\n",
       "      <td>-6.592</td>\n",
       "      <td>-440.997704</td>\n",
       "      <td>396.201804</td>\n",
       "      <td>5.380286</td>\n",
       "      <td>1052.845164</td>\n",
       "      <td>11.751212</td>\n",
       "      <td>1.049894</td>\n",
       "      <td>-247.94549</td>\n",
       "      <td>-34.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>1595</td>\n",
       "      <td>Gryffindor</td>\n",
       "      <td>Jung</td>\n",
       "      <td>Blank</td>\n",
       "      <td>2001-09-14</td>\n",
       "      <td>Right</td>\n",
       "      <td>49009.0</td>\n",
       "      <td>354.280086</td>\n",
       "      <td>-4.541837</td>\n",
       "      <td>-3.542801</td>\n",
       "      <td>5.702</td>\n",
       "      <td>-497.235066</td>\n",
       "      <td>618.220213</td>\n",
       "      <td>-5.231721</td>\n",
       "      <td>964.219853</td>\n",
       "      <td>3.389086</td>\n",
       "      <td>-0.649983</td>\n",
       "      <td>-250.39401</td>\n",
       "      <td>185.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>1596</td>\n",
       "      <td>Slytherin</td>\n",
       "      <td>Shelli</td>\n",
       "      <td>Lock</td>\n",
       "      <td>1998-03-12</td>\n",
       "      <td>Left</td>\n",
       "      <td>63296.0</td>\n",
       "      <td>367.531174</td>\n",
       "      <td>6.061064</td>\n",
       "      <td>-3.675312</td>\n",
       "      <td>1.757</td>\n",
       "      <td>-643.271092</td>\n",
       "      <td>445.827565</td>\n",
       "      <td>2.238112</td>\n",
       "      <td>1056.147366</td>\n",
       "      <td>5.825263</td>\n",
       "      <td>-0.333962</td>\n",
       "      <td>-246.42719</td>\n",
       "      <td>44.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>1597</td>\n",
       "      <td>Gryffindor</td>\n",
       "      <td>Benjamin</td>\n",
       "      <td>Christensen</td>\n",
       "      <td>1999-10-24</td>\n",
       "      <td>Right</td>\n",
       "      <td>63905.0</td>\n",
       "      <td>544.018925</td>\n",
       "      <td>-3.203269</td>\n",
       "      <td>-5.440189</td>\n",
       "      <td>6.065</td>\n",
       "      <td>-385.150457</td>\n",
       "      <td>635.211486</td>\n",
       "      <td>-5.984257</td>\n",
       "      <td>953.866685</td>\n",
       "      <td>1.709808</td>\n",
       "      <td>0.071569</td>\n",
       "      <td>-251.63679</td>\n",
       "      <td>198.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>1598</td>\n",
       "      <td>Hufflepuff</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>Dillon</td>\n",
       "      <td>2001-09-21</td>\n",
       "      <td>Left</td>\n",
       "      <td>82713.0</td>\n",
       "      <td>453.676219</td>\n",
       "      <td>3.442831</td>\n",
       "      <td>-4.536762</td>\n",
       "      <td>6.738</td>\n",
       "      <td>-831.741123</td>\n",
       "      <td>383.444937</td>\n",
       "      <td>3.813111</td>\n",
       "      <td>1087.949205</td>\n",
       "      <td>3.904100</td>\n",
       "      <td>-0.531875</td>\n",
       "      <td>-246.19072</td>\n",
       "      <td>-76.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>1599</td>\n",
       "      <td>Hufflepuff</td>\n",
       "      <td>Kylie</td>\n",
       "      <td>Nowak</td>\n",
       "      <td>2000-08-21</td>\n",
       "      <td>Left</td>\n",
       "      <td>48639.0</td>\n",
       "      <td>688.911989</td>\n",
       "      <td>5.421046</td>\n",
       "      <td>-6.889120</td>\n",
       "      <td>6.593</td>\n",
       "      <td>-234.207911</td>\n",
       "      <td>339.775154</td>\n",
       "      <td>7.208415</td>\n",
       "      <td>1034.928004</td>\n",
       "      <td>2.052215</td>\n",
       "      <td>0.150532</td>\n",
       "      <td>-244.02063</td>\n",
       "      <td>-54.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1251 rows × 19 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic Regression\n",
    "### Log loss\n",
    "The log loss function is used to evaluate the performance of a classification model. It is defined as follows\n",
    "With y_true representing the true labels and y_pred representing the predicted labels.\n",
    "The log loss is also known as the cross-entropy loss."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b62c0d89975aafc"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3721961876540016\n"
     ]
    }
   ],
   "source": [
    "def log_loss(y_true, y_pred):\n",
    "    y_pred = np.clip(y_pred, 1e-7, 1 - 1e-7) # Clip the values to avoid log(0)\n",
    "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "\n",
    "# Example log loss\n",
    "y_true_sample = np.array([0, 1, 1, 0, 1])\n",
    "y_pred_sample = np.array([0.1, 0.9, 0.8, 0.2, 0.3])\n",
    "print(log_loss(y_true_sample, y_pred_sample))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T19:08:29.504258Z",
     "start_time": "2024-03-23T19:08:29.500560Z"
    }
   },
   "id": "f17c706e58411b3f",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4ef2d2e18493d1a3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hypothesis\n",
    "The hypothesis function for logistic regression is defined as follows\n",
    "With theta represents the weights of the features and x represents the features of the sample."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11c04556267c4946"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7310585786300049\n",
      "0.8320183851339245\n",
      "[0.83201839 0.84553473 0.85814894]\n"
     ]
    }
   ],
   "source": [
    "def hypothesis(x, theta):\n",
    "    return 1 / (1 + np.exp(-x @ theta))\n",
    "\n",
    "# Example hypothesis one feature\n",
    "x = np.array([2])\n",
    "theta = np.array([0.5])\n",
    "print(hypothesis(x, theta))\n",
    "\n",
    "# Example hypothesis multiple features\n",
    "x = np.array([1, 3, 4]) #  1 = bias , 3 = feature_1_value, 4 = feature_2_value\n",
    "theta = np.array([0.5, 0.1, 0.2]) # 0.5 = bias, 0.1 = feature_1_weight, 0.2 = feature_2_weight\n",
    "print(hypothesis(x, theta))\n",
    "\n",
    "# Example hypothesis multiple features and multiple samples\n",
    "x = np.array([[1, 3, 4], [1, 2, 5], [1, 1, 6]]) #  1,3,4 = bias , 1,2,5 = feature_1_value, 1,1,6 = feature_2_value\n",
    "theta = np.array([0.5, 0.1, 0.2]) # 0.5 = bias, 0.1 = feature_1_weight, 0.2 = feature_2_weight\n",
    "print(hypothesis(x, theta))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T19:08:31.132264Z",
     "start_time": "2024-03-23T19:08:31.126454Z"
    }
   },
   "id": "983cbc6f17948f3",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gradient\n",
    "### Stochastic Gradient Descent"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7690c051fdcb381d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started: 1251 samples, 100 epochs, learning rate: 0.1..., theta: [0. 0. 0. 0. 0.]...\n",
      "Training finished: 0.043928097381231906 log loss, [-3.49393424 -1.42931541  0.08829902  2.65178519 -0.98121965]... theta \n",
      "\n",
      "Training started: 1251 samples, 100 epochs, learning rate: 0.1..., theta: [0. 0. 0. 0. 0.]...\n",
      "Training finished: 0.03224474011334483 log loss, [-5.01218535 -0.12494031  1.7422377  -2.69615217 -1.34418688]... theta \n",
      "\n",
      "Training started: 1251 samples, 100 epochs, learning rate: 0.1..., theta: [0. 0. 0. 0. 0.]...\n",
      "Training finished: 0.06884723621325846 log loss, [-2.54566817  0.69361317  1.26035852 -0.16782006  1.98025976]... theta \n",
      "\n",
      "Training started: 1251 samples, 100 epochs, learning rate: 0.1..., theta: [0. 0. 0. 0. 0.]...\n",
      "Training finished: 0.05539857675761649 log loss, [-2.75768722  2.20759903 -2.47567216  0.49343251 -1.20589351]... theta \n",
      "\n",
      "To conclude, the final theta is: \n"
     ]
    },
    {
     "data": {
      "text/plain": "{'gryffindor': array([-3.49393424, -1.42931541,  0.08829902,  2.65178519, -0.98121965,\n         0.29406253, -0.71393398, -1.52340126,  0.02341803,  0.87885243,\n         1.69819368]),\n 'slytherin': array([-5.01218535, -0.12494031,  1.7422377 , -2.69615217, -1.34418688,\n        -0.37271187, -0.61308514,  1.26330958,  1.37367699, -0.45238373,\n         0.02434027]),\n 'ravenclaw': array([-2.54566817,  0.69361317,  1.26035852, -0.16782006,  1.98025976,\n         1.53430769,  0.16579869,  0.01871794, -0.29523291,  1.10897304,\n        -0.34593762]),\n 'hufflepuff': array([-2.75768722,  2.20759903, -2.47567216,  0.49343251, -1.20589351,\n        -0.8207735 ,  1.70485264,  0.16457834, -0.81004128, -0.8596664 ,\n        -1.0648127 ])}"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stochastic_gradient_descent(x, y_true, theta, learning_rate, epochs):\n",
    "    m = x.shape[0]\n",
    "    print(f'Training started: {m} samples, {epochs} epochs, learning rate: {learning_rate}..., theta: {theta[:5]}...')\n",
    "    theta_train_loop = theta.copy()\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(m):\n",
    "            random_index = np.random.randint(m)\n",
    "            x_i = x[random_index:random_index + 1]\n",
    "            y_i = y_true[random_index:random_index + 1]\n",
    "            y_pred = hypothesis(x_i, theta_train_loop)\n",
    "            gradient = x_i.T @ (y_pred - y_i)\n",
    "            theta_train_loop -= learning_rate * gradient\n",
    "    print(f'Training finished: {log_loss(y_true, hypothesis(x, theta_train_loop))} log loss, {theta_train_loop[:5]}... theta \\n')\n",
    "    return theta_train_loop\n",
    "\n",
    "bias = np.ones((x_train_standardized.shape[0], 1)) # Create a column of ones for the bias, with x_train.shape[0] = number of rows, so we create a column of ones with the same number of rows as x_train plus one column, the bias\n",
    "x_bias = np.hstack([bias, x_train_standardized]) # Add the bias column to the x_train\n",
    "initial_theta = np.zeros(x_bias.shape[1])\n",
    "theta_train = {\n",
    "    'gryffindor': stochastic_gradient_descent(x_bias, y_true['gryffindor'], initial_theta , 0.1, 100),\n",
    "    'slytherin': stochastic_gradient_descent(x_bias, y_true['slytherin'], initial_theta, 0.1, 100),\n",
    "    'ravenclaw': stochastic_gradient_descent(x_bias, y_true['ravenclaw'], initial_theta, 0.1, 100),\n",
    "    'hufflepuff': stochastic_gradient_descent(x_bias, y_true['hufflepuff'], initial_theta, 0.1, 100)\n",
    "}\n",
    "\n",
    "print(\"To conclude, the final theta is: \")\n",
    "theta_train\n",
    "# features = train_data_filtered.columns.insert(0, 'Bias')\n",
    "# theta_dict = dict(zip(features, theta_train))\n",
    "# theta_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T18:34:40.419276Z",
     "start_time": "2024-03-23T18:34:16.468884Z"
    }
   },
   "id": "dd4111f57d8d705",
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Store theta train"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "115777d6a9167e9e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Store theta train: {'gryffindor': array([-3.49393424, -1.42931541,  0.08829902,  2.65178519, -0.98121965,\n",
      "        0.29406253, -0.71393398, -1.52340126,  0.02341803,  0.87885243,\n",
      "        1.69819368]), 'slytherin': array([-5.01218535, -0.12494031,  1.7422377 , -2.69615217, -1.34418688,\n",
      "       -0.37271187, -0.61308514,  1.26330958,  1.37367699, -0.45238373,\n",
      "        0.02434027]), 'ravenclaw': array([-2.54566817,  0.69361317,  1.26035852, -0.16782006,  1.98025976,\n",
      "        1.53430769,  0.16579869,  0.01871794, -0.29523291,  1.10897304,\n",
      "       -0.34593762]), 'hufflepuff': array([-2.75768722,  2.20759903, -2.47567216,  0.49343251, -1.20589351,\n",
      "       -0.8207735 ,  1.70485264,  0.16457834, -0.81004128, -0.8596664 ,\n",
      "       -1.0648127 ])}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "def store_theta_train(theta_train):\n",
    "    # Store data (serialize)\n",
    "    with open('../results/models/theta_train.pkl', 'wb') as handle:\n",
    "        pickle.dump(theta_train, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        print(\"Store theta train:\", theta_train)\n",
    "\n",
    "def load_theta_train():\n",
    "    # Load data (deserialize)\n",
    "    with open('../results/models/theta_train.pkl', 'rb') as handle:\n",
    "        theta_train = pickle.load(handle)\n",
    "        print(\"Theta_train loaded:\", theta_train)\n",
    "        return theta_train\n",
    "        \n",
    "store_theta_train(theta_train)\n",
    "# theta_train = load_theta_train()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T18:36:20.710574Z",
     "start_time": "2024-03-23T18:36:20.703151Z"
    }
   },
   "id": "c9abfa707e722160",
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predict"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d4582f453708d71"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "      gryffindor  slytherin  ravenclaw  hufflepuff\n0       0.005994   0.000634   0.974236    0.023482\n1       0.000011   0.997004   0.004863    0.004103\n2       0.005530   0.001438   0.997832    0.001417\n3       0.998456   0.000031   0.000263    0.007349\n4       0.000024   0.999604   0.011709    0.000551\n...          ...        ...        ...         ...\n1246    0.997998   0.000168   0.006202    0.000568\n1247    0.002910   0.050052   0.003950    0.881303\n1248    0.998389   0.000020   0.008622    0.001880\n1249    0.005656   0.002752   0.000716    0.995412\n1250    0.004992   0.000016   0.005201    0.999324\n\n[1251 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gryffindor</th>\n      <th>slytherin</th>\n      <th>ravenclaw</th>\n      <th>hufflepuff</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.005994</td>\n      <td>0.000634</td>\n      <td>0.974236</td>\n      <td>0.023482</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000011</td>\n      <td>0.997004</td>\n      <td>0.004863</td>\n      <td>0.004103</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.005530</td>\n      <td>0.001438</td>\n      <td>0.997832</td>\n      <td>0.001417</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.998456</td>\n      <td>0.000031</td>\n      <td>0.000263</td>\n      <td>0.007349</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000024</td>\n      <td>0.999604</td>\n      <td>0.011709</td>\n      <td>0.000551</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1246</th>\n      <td>0.997998</td>\n      <td>0.000168</td>\n      <td>0.006202</td>\n      <td>0.000568</td>\n    </tr>\n    <tr>\n      <th>1247</th>\n      <td>0.002910</td>\n      <td>0.050052</td>\n      <td>0.003950</td>\n      <td>0.881303</td>\n    </tr>\n    <tr>\n      <th>1248</th>\n      <td>0.998389</td>\n      <td>0.000020</td>\n      <td>0.008622</td>\n      <td>0.001880</td>\n    </tr>\n    <tr>\n      <th>1249</th>\n      <td>0.005656</td>\n      <td>0.002752</td>\n      <td>0.000716</td>\n      <td>0.995412</td>\n    </tr>\n    <tr>\n      <th>1250</th>\n      <td>0.004992</td>\n      <td>0.000016</td>\n      <td>0.005201</td>\n      <td>0.999324</td>\n    </tr>\n  </tbody>\n</table>\n<p>1251 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(x, theta):\n",
    "    bias = np.ones((x.shape[0], 1))\n",
    "    x_bias = np.hstack([bias, x])\n",
    "    probabilities = {\n",
    "        'gryffindor': hypothesis(x_bias, theta['gryffindor']),\n",
    "        'slytherin': hypothesis(x_bias, theta['slytherin']),\n",
    "        'ravenclaw': hypothesis(x_bias, theta['ravenclaw']),\n",
    "        'hufflepuff': hypothesis(x_bias, theta['hufflepuff'])\n",
    "    }\n",
    "    return pd.DataFrame(probabilities)\n",
    "\n",
    "predict(x_train_standardized, theta_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T18:52:55.408822Z",
     "start_time": "2024-03-23T18:52:55.331171Z"
    }
   },
   "id": "46f4a9b57a2b41b2",
   "execution_count": 56
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compare with sklearn"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93a83dc8ecd736d5"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.16222735 -0.48711888  1.48263139 -0.31693973  0.86561988 -0.57019407\n",
      " -1.32198748  0.20903784 -0.00532947  1.09389221]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "sgd = SGDClassifier(loss='log_loss', learning_rate='constant', max_iter=100, tol=1e-7, random_state=42, eta0=0.1)\n",
    "sgd.fit(x_train_standardized, y_true['gryffindor'])\n",
    "print(sgd.coef_[0])\n",
    "theta_train['gryffindor'] - np.hstack([sgd.intercept_, sgd.coef_[0]])\n",
    "x_test = pd.read_csv('../data/raw/dataset_test.csv')\n",
    "x_test_filtered = x_test.drop(columns = ['First Name', 'Last Name', 'Birthday', 'Best Hand', 'Index', 'Astronomy', 'Arithmancy', 'Care of Magical Creatures', 'Hogwarts House']).dropna()\n",
    "\n",
    "# accuracy_score(sgd.predict(standardize(x_test_filtered)), predict(x_test_filtered, theta_train)['gryffindor'])\n",
    "# predict(standardize(x_test_filtered), theta_train)['gryffindor']\n",
    "binary_predictions = predict(standardize(x_test_filtered), theta_train)['gryffindor'].apply(lambda x: 1 if x > 0.5 else 0)\n",
    "print(accuracy_score(sgd.predict(standardize(x_test_filtered)), binary_predictions))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T18:58:46.807670Z",
     "start_time": "2024-03-23T18:58:46.792539Z"
    }
   },
   "id": "c45897c87ebe8213",
   "execution_count": 67
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Optimisation bonus : mini-batch gd "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85842b4aa34f6d56"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started: 1251 samples, 100 epochs, learning rate: 0.1, batch size: 32..., theta: [0. 0. 0. 0. 0.]...\n",
      "Training finished: 0.04203245972395851 log loss, [-3.68655132 -1.60916743 -0.02186867  2.4397184  -0.49515849]... theta \n"
     ]
    },
    {
     "data": {
      "text/plain": "array([-3.68655132, -1.60916743, -0.02186867,  2.4397184 , -0.49515849,\n        0.06369299, -0.41579199, -1.63988086,  0.23750852,  0.83526254,\n        1.54687037])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mini_batch_gradient_descent(x, y_true, theta, learning_rate, epochs, batch_size):\n",
    "    m = x.shape[0]\n",
    "    print(f'Training started: {m} samples, {epochs} epochs, learning rate: {learning_rate}, batch size: {batch_size}..., theta: {theta[:5]}...')\n",
    "    theta_train_loop = theta.copy()\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0, m, batch_size):\n",
    "            x_i = x[i:i + batch_size]\n",
    "            y_i = y_true[i:i + batch_size]\n",
    "            y_pred = hypothesis(x_i, theta_train_loop)\n",
    "            gradient = x_i.T @ (y_pred - y_i)\n",
    "            theta_train_loop -= learning_rate * gradient\n",
    "    print(f'Training finished: {log_loss(y_true, hypothesis(x, theta_train_loop))} log loss, {theta_train_loop[:5]}... theta \\n')\n",
    "    return theta_train_loop\n",
    "bias = np.ones((x_train_standardized.shape[0], 1)) # Create a column of ones for the bias, with x_train.shape[0] = number of rows, so we create a column of ones with the same number of rows as x_train plus one column, the bias\n",
    "x_bias = np.hstack([bias, x_train_standardized]) # Add the bias column to the x_train\n",
    "initial_theta = np.zeros(x_bias.shape[1])\n",
    "mini_batch_gradient_descent(x_bias, y_true['gryffindor'], initial_theta, 0.1, 100, 32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T19:09:23.551711Z",
     "start_time": "2024-03-23T19:09:23.113443Z"
    }
   },
   "id": "28f239de7676fd44",
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
